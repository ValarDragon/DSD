{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 22500\n"
     ]
    }
   ],
   "source": [
    "test_img_fnames = os.listdir('data/data/test')\n",
    "train_img_fnames = os.listdir('data/data/train')\n",
    "percentage_data_size = 5 / 100\n",
    "print(len(test_img_fnames), len(train_img_fnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the data\n",
    "First we need to write a function to load into memory each of the images, and then resize them to (224, 224, 3). scipy.misc.imread and scipy.misc.imresize will be useful for this. You should also rescale the images so that they are on a scale of 0 to 1, meaning each pixel value should be between 0 and 1. This can be achieved by dividing by an appropriate constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_img(filename):\n",
    "    img = misc.imread(filename)\n",
    "    img = misc.imresize(img, (224,224))\n",
    "    return img / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_imgs = [load_img(os.path.join('data/test', fname)) for fname in test_img_fnames[:int(len(test_img_fnames) * percentage_data_size)]]\n",
    "test_imgs = np.stack(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = [load_img(os.path.join('data/data/train', fname)) for fname in train_img_fnames[:int(len(train_img_fnames) * percentage_data_size)]]\n",
    "train_imgs = np.stack(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/train_labels.pkl', 'rb') as f:\n",
    "    train_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained VGG network\n",
    "Now in order to generate the CNN featurizations of our images we need to load a pretrained network. Note that running this network will take a long time on CPU so you can feel free to skip this section and just load the featurizations I provided in the next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG16 = keras.applications.vgg16.VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featurized_training_data = VGG16.predict(train_imgs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featurized_test_data = VGG16.predict(test_imgs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'featurized_training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7f27c8f7a7cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/featurized_train_imgs_gen.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturized_training_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/featurized_test_imgs_gen.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturized_test_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'featurized_training_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Save featurizations, I changed filenames so as not to overwrite the original\n",
    "import pickle\n",
    "with open('featurized_train_imgs_gen.pkl', 'wb') as f:\n",
    "    pickle.dump(featurized_training_data, f)\n",
    "with open('featurized_test_imgs_gen.pkl', 'wb') as f:\n",
    "    pickle.dump(featurized_test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load featurizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('featurized_train_imgs.pkl', 'rb') as f:\n",
    "    featurized_training_data = pickle.load(f)\n",
    "with open('featurized_test_imgs.pkl', 'rb') as f:\n",
    "    featurized_test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create you network\n",
    "Now we need to create a network to take in the featurizations and output a label of dog or not dog. To do this you should use Keras' Sequential model. We will need to flatten our (7,7,512) feature input into a vector (HINT: lookup flatten in keras documentation) and then add a Dense layer with some number of neurons (play around with the number of neurons to improve your performance). Then finally we need a Dense layer with 1 neuron and a sigmoid activation to represent our label output. You might want to use more or less model.add calls than have been provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(7,7,512)))\n",
    "model.add(keras.layers.Dense(60, activation=\"tanh\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                1505340   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                610       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,505,961\n",
      "Trainable params: 1,505,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we need to train the network\n",
    "You need to compile the model first, and then use the fit function. You should use binary crossentropy as your loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "10000/10000 [==============================] - 10s - loss: 0.5887    \n",
      "Epoch 2/15\n",
      "10000/10000 [==============================] - 9s - loss: 0.3964     \n",
      "Epoch 3/15\n",
      "10000/10000 [==============================] - 9s - loss: 0.3149     \n",
      "Epoch 4/15\n",
      "10000/10000 [==============================] - 8s - loss: 0.2818     \n",
      "Epoch 5/15\n",
      "10000/10000 [==============================] - 8s - loss: 0.2707     \n",
      "Epoch 6/15\n",
      "10000/10000 [==============================] - 8s - loss: 0.2409     \n",
      "Epoch 7/15\n",
      "10000/10000 [==============================] - 8s - loss: 0.2199     \n",
      "Epoch 8/15\n",
      "10000/10000 [==============================] - 8s - loss: 0.2114     \n",
      "Epoch 9/15\n",
      "10000/10000 [==============================] - 8s - loss: 0.2017     \n",
      "Epoch 10/15\n",
      "10000/10000 [==============================] - 8s - loss: 0.1980     \n",
      "Epoch 11/15\n",
      "10000/10000 [==============================] - 8s - loss: 0.1802     \n",
      "Epoch 12/15\n",
      "10000/10000 [==============================] - 8s - loss: 0.1770     \n",
      "Epoch 13/15\n",
      "10000/10000 [==============================] - 10s - loss: 0.1631    \n",
      "Epoch 14/15\n",
      "10000/10000 [==============================] - 8s - loss: 0.1716     \n",
      "Epoch 15/15\n",
      "10000/10000 [==============================] - 8s - loss: 0.1490     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ca80110780>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(featurized_training_data, train_labels, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to predict labels for the test set and output it to file. Use keras predict for this. Remember that the predictions are real values between 0 and 1 and you should be outputting just 0 or 1, not a value between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(featurized_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = '4_dev'\n",
    "with open('test_labels_%s.txt' % i, 'w') as f:\n",
    "    f.write(\"Id,Label\\n\")\n",
    "    for i, val in enumerate(predictions):\n",
    "        prediction = 0 if val < .5 else 1\n",
    "        f.write(str(i))\n",
    "        f.write(',')\n",
    "        f.write(str(prediction))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "93\n",
      "154\n",
      "174\n",
      "195\n",
      "215\n",
      "Disagreement on 296 , with unknown result\n",
      "322\n",
      "Disagreement on 378 , with unknown result\n",
      "Disagreement on 397 , with unknown result\n",
      "Disagreement on 418 , with unknown result\n",
      "Disagreement on 438 , with unknown result\n",
      "Disagreement on 452 , with unknown result\n",
      "Disagreement on 494 , with unknown result\n",
      "524\n",
      "Disagreement on 544 , with unknown result\n",
      "Disagreement on 564 , with unknown result\n",
      "Disagreement on 575 , with unknown result\n",
      "Disagreement on 597 , with unknown result\n",
      "Disagreement on 604 , with unknown result\n",
      "Disagreement on 610 , with unknown result\n",
      "Disagreement on 624 , with unknown result\n",
      "Disagreement on 641 , with unknown result\n",
      "Disagreement on 715 , with unknown result\n",
      "Disagreement on 719 , with unknown result\n",
      "Disagreement on 726 , with unknown result\n",
      "Disagreement on 740 , with unknown result\n",
      "Disagreement on 749 , with unknown result\n",
      "Disagreement on 750 , with unknown result\n",
      "Disagreement on 761 , with unknown result\n",
      "Disagreement on 766 , with unknown result\n",
      "Disagreement on 849 , with unknown result\n",
      "Disagreement on 857 , with unknown result\n",
      "Disagreement on 879 , with unknown result\n",
      "913\n",
      "Disagreement on 946 , with unknown result\n",
      "Disagreement on 972 , with unknown result\n",
      "Disagreement on 986 , with unknown result\n",
      "Disagreement on 999 , with unknown result\n",
      "Disagreement on 1120 , with unknown result\n",
      "Disagreement on 1149 , with unknown result\n",
      "Disagreement on 1172 , with unknown result\n",
      "Disagreement on 1176 , with unknown result\n",
      "Disagreement on 1179 , with unknown result\n",
      "Disagreement on 1215 , with unknown result\n",
      "Disagreement on 1216 , with unknown result\n",
      "Disagreement on 1231 , with unknown result\n",
      "Disagreement on 1239 , with unknown result\n",
      "Disagreement on 1264 , with unknown result\n",
      "Disagreement on 1306 , with unknown result\n",
      "Disagreement on 1324 , with unknown result\n",
      "Disagreement on 1326 , with unknown result\n",
      "Disagreement on 1364 , with unknown result\n",
      "Disagreement on 1367 , with unknown result\n",
      "Disagreement on 1401 , with unknown result\n",
      "Disagreement on 1407 , with unknown result\n",
      "Disagreement on 1454 , with unknown result\n",
      "Disagreement on 1458 , with unknown result\n",
      "Disagreement on 1464 , with unknown result\n",
      "Disagreement on 1482 , with unknown result\n",
      "Disagreement on 1489 , with unknown result\n",
      "Disagreement on 1497 , with unknown result\n",
      "Disagreement on 1521 , with unknown result\n",
      "Disagreement on 1539 , with unknown result\n",
      "Disagreement on 1550 , with unknown result\n",
      "Disagreement on 1571 , with unknown result\n",
      "Disagreement on 1577 , with unknown result\n",
      "Disagreement on 1601 , with unknown result\n",
      "Disagreement on 1602 , with unknown result\n",
      "Disagreement on 1619 , with unknown result\n",
      "Disagreement on 1633 , with unknown result\n",
      "Disagreement on 1638 , with unknown result\n",
      "Disagreement on 1640 , with unknown result\n",
      "Disagreement on 1654 , with unknown result\n",
      "Disagreement on 1666 , with unknown result\n",
      "Disagreement on 1669 , with unknown result\n",
      "Disagreement on 1670 , with unknown result\n",
      "Disagreement on 1685 , with unknown result\n",
      "Disagreement on 1710 , with unknown result\n",
      "Disagreement on 1718 , with unknown result\n",
      "Disagreement on 1724 , with unknown result\n",
      "Disagreement on 1745 , with unknown result\n",
      "Disagreement on 1770 , with unknown result\n",
      "Disagreement on 1782 , with unknown result\n",
      "Disagreement on 1787 , with unknown result\n",
      "Disagreement on 1797 , with unknown result\n",
      "Disagreement on 1804 , with unknown result\n",
      "Disagreement on 1825 , with unknown result\n",
      "Disagreement on 1842 , with unknown result\n",
      "Disagreement on 1843 , with unknown result\n",
      "Disagreement on 1858 , with unknown result\n",
      "Disagreement on 1865 , with unknown result\n",
      "Disagreement on 1875 , with unknown result\n",
      "Disagreement on 1888 , with unknown result\n",
      "Disagreement on 1891 , with unknown result\n",
      "Disagreement on 1905 , with unknown result\n",
      "Disagreement on 1937 , with unknown result\n",
      "Disagreement on 1938 , with unknown result\n",
      "Disagreement on 2011 , with unknown result\n",
      "Disagreement on 2018 , with unknown result\n",
      "Disagreement on 2032 , with unknown result\n",
      "Disagreement on 2038 , with unknown result\n",
      "Disagreement on 2044 , with unknown result\n",
      "Disagreement on 2055 , with unknown result\n",
      "Disagreement on 2088 , with unknown result\n",
      "Disagreement on 2119 , with unknown result\n",
      "Disagreement on 2127 , with unknown result\n",
      "Disagreement on 2143 , with unknown result\n",
      "Disagreement on 2146 , with unknown result\n",
      "Disagreement on 2172 , with unknown result\n",
      "Disagreement on 2175 , with unknown result\n",
      "Disagreement on 2202 , with unknown result\n",
      "Disagreement on 2209 , with unknown result\n",
      "Disagreement on 2216 , with unknown result\n",
      "Disagreement on 2238 , with unknown result\n",
      "Disagreement on 2241 , with unknown result\n",
      "Disagreement on 2245 , with unknown result\n",
      "Disagreement on 2276 , with unknown result\n",
      "Disagreement on 2286 , with unknown result\n",
      "2319\n",
      "Disagreement on 2324 , with unknown result\n",
      "Disagreement on 2340 , with unknown result\n",
      "Disagreement on 2375 , with unknown result\n",
      "Disagreement on 2378 , with unknown result\n",
      "Disagreement on 2379 , with unknown result\n",
      "Disagreement on 2402 , with unknown result\n",
      "Disagreement on 2421 , with unknown result\n",
      "Disagreement on 2452 , with unknown result\n",
      "2461\n",
      "2496\n",
      "model 1 scored 9 more than model 2\n",
      "Net number of different lines is 151\n",
      "model 1 had 12 wrong lines\n",
      "on top of that, both models had 1 wrong\n",
      "Number of unknown lines is 118\n"
     ]
    }
   ],
   "source": [
    "# Add disagreeing images manually here. cats are 1, dogs are 0 \n",
    "known_dic = {0:0, 16:1, 23:1, 59:1, 79:1, 85:0, 89:1, 93:0, 107:1, 116:1, 132:1, 154:0, 322:0,\n",
    "            279:1, 271:1, 215:0, 202:1, 195:0, 174:0, 154:0, 335:1, 366:1, 350:1, 351:1, 524:0, 525:1, 1065:1, 1069:1,\n",
    "            913:0, 923:1,2313:1, 2319:0, 2321:1, 2496: 0, 2461:0}\n",
    "def compare_files(f1, f2):\n",
    "    f1 = open(f1,'r')\n",
    "    f2 = open(f2,'r')\n",
    "    f1.readline()\n",
    "    f2.readline()\n",
    "    count, netdif, unknowns, wrong, both_wrong = 0, 0, 0, 0, 0\n",
    "    for line_num in range(2500):\n",
    "        mod_1 = f1.readline()\n",
    "        pred_1 = int(mod_1[mod_1.index(\",\")+1:][:-1])\n",
    "        mod_2 = f2.readline()\n",
    "        pred_2 = int(mod_2[mod_2.index(\",\")+1:][:-1])\n",
    "        if pred_2 != pred_1:\n",
    "            netdif += 1\n",
    "            if line_num in known_dic:\n",
    "                if known_dic[line_num] == pred_1:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    count -= 1\n",
    "                    print(line_num)\n",
    "                    wrong += 1\n",
    "            else:\n",
    "                print(\"Disagreement on %s , with unknown result\" % line_num)\n",
    "                unknowns += 1\n",
    "        else:\n",
    "            if line_num in known_dic and known_dic[line_num] != mod_2: both_wrong += 1; \n",
    "                \n",
    "    print(\"model 1 scored \" + str(count) + \" more than model 2\")\n",
    "    print(\"Net number of different lines is \" + str(netdif))\n",
    "    print(\"model 1 had %s wrong lines\" % str(wrong))\n",
    "    print(\"on top of that, both models had %s wrong\" % both_wrong)\n",
    "    print(\"Number of unknown lines is \" + str(unknowns))\n",
    "compare_files('test_labels_2.txt','test_labels_1.txt')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to run PCA on our images and our featurizations to see the difference. To save time we will just run it on the first 500 images. Take the first 500 images and 500 featurizations and reshape them into shape (500, x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_imgs = np.reshape(train_imgs[:500], (500, 224*224*3))\n",
    "featurized = np.reshape(featurized_training_data[:500], (500, 7*7*512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PCA with 2 components on the original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_orig = PCA(n_components=2)\n",
    "pca_orig.fit(original_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PCA with 2 components on the featurizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_featurized = PCA(n_components=2)\n",
    "pca_featurized = pca_featurized.fit(featurized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project the original images and featurizations onto the 2 principal components. (HINT: look at the PCA.transform function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "projected_orig_imgs = pca_orig.transform(original_imgs)\n",
    "projected_featurized = pca_featurized.transform(featurized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the indices of the labels that are cats and the indices that are dogs. np.where will make this very easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-37-d80a0339e5d7>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-37-d80a0339e5d7>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    cat_inds = ???\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "labels = train_labels[:500]\n",
    "cat_inds = np.where(labels,)\n",
    "dog_inds = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the PCA of the original images and the PCA of the featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(projected_orig_imgs[cat_inds ,0], projected_orig_imgs[cat_inds, 1], c='red')\n",
    "plt.scatter(projected_orig_imgs[dog_inds, 0], projected_orig_imgs[dog_inds, 1], c='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(projected_featurized[cat_inds ,0], projected_featurized[cat_inds, 1], c='red')\n",
    "plt.scatter(projected_featurized[dog_inds, 0], projected_featurized[dog_inds, 1], c='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
